{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pkj7An36-uF5"
      },
      "source": [
        "<a href=\"https://githubtocolab.com/jmvazqueznicolas/sistemas_inteligentes_22-1/blob/master/P7_Sistemas%20Inteligentes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mN0YizjQ9tFX"
      },
      "source": [
        "## Práctica 7. Sistemas Inteligentes\n",
        "\n",
        "### Objetivos\n",
        "#### 1.- Que el alumno implemente una red neuronal convolucional.\n",
        "### Marco teórico\n",
        "#### El alumno debe investigar lo que son las redes neuronales convolucionales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dLcoHi7T3M78"
      },
      "outputs": [],
      "source": [
        "# Accediendo a Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tQU5pOe-3SIt"
      },
      "outputs": [],
      "source": [
        "# Copiamos los archivos de Drive al entorno de Colab\n",
        "!cp \"____\" \"Neumonia_Dataset.zip\"\n",
        "!unzip -uq \"Neumonia_Dataset.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BKYZblKxf6OL"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas a emplear\n",
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from ____ import ____\n",
        "from ____ import ____\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "deGsd93ChxWW"
      },
      "outputs": [],
      "source": [
        "# Definir las rutas donde estan las imagenes\n",
        "train_folder= '/content/Neumonia_Dataset/train'\n",
        "val_folder = '/content/Neumonia_Dataset/val'\n",
        "test_folder = '/content/Neumonia_Dataset/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xGLu8oYjliRG"
      },
      "outputs": [],
      "source": [
        "# Se toman 4 imagenes de forma aleatoria\n",
        "os.listdir(train_folder)\n",
        "train_sanas = ____+'/NORMAL/'\n",
        "train_neum = ____+'/PNEUMONIA/'\n",
        "img_sanas = []\n",
        "img_neumonia = []\n",
        "for i in ____(4):\n",
        "    num_alea = np.random.randint(len(os.listdir(train_sanas)))\n",
        "    img_sanas.append(train_sanas + os.listdir(train_sanas)[num_alea])\n",
        "    img_neumonia.append(train_neum + os.listdir(train_neum)[num_alea])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pob4LA4uq4-_"
      },
      "outputs": [],
      "source": [
        "# Se muestran radiografías de personas con y sin neumonía\n",
        "print('Primer fila: personas sin neumonía')\n",
        "print('Segunda fila: personas con neumonía')\n",
        "plt.rcParams['figure.dpi'] = 150\n",
        "for num_imagen in ____(8):\n",
        "    if num_imagen<4:\n",
        "        imagen = cv2.imread(img_sanas[num_imagen])\n",
        "    else:\n",
        "        imagen = cv2.imread(img_neumonia[num_imagen-4])\n",
        "    plt.subplot(2,4,num_imagen+1)\n",
        "    plt.imshow(____)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "arbunxo2td_n"
      },
      "outputs": [],
      "source": [
        "# Red neuronal convolucional\n",
        "cnn = models.Sequential()\n",
        "\n",
        "# Capas convolucionales y de pooling\n",
        "cnn.add(layers.____(32, (3, 3), activation=\"relu\", input_shape=(150, 150, 3)))\n",
        "cnn.add(layers.____(pool_size = (2, 2)))\n",
        "cnn.add(layers.____(32, (3, 3), activation=\"relu\"))\n",
        "cnn.add(layers.____(pool_size = (2, 2)))\n",
        "cnn.add(layers.____(32, (3, 3), activation=\"relu\"))\n",
        "cnn.add(layers.____(pool_size = (2, 2)))\n",
        "cnn.add(layers.____())\n",
        "\n",
        "# Capas densamente conectadas\n",
        "cnn.add(layers.____(activation = 'relu', units = 128))\n",
        "cnn.add(layers.____(activation = 'sigmoid', units = 1))\n",
        "\n",
        "# Compilar el modelo neuronal\n",
        "cnn.____(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LB_MZ6Mk5WIK"
      },
      "outputs": [],
      "source": [
        "# Detalle de la red neuronal convolucional\n",
        "cnn.____()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WQV293BqtpBC"
      },
      "outputs": [],
      "source": [
        "# Preprocesamiento de las imagenes\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "# Normalización de imagenes\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# Generación de los conjuntos de entrenamiento, validación y prrueba\n",
        "training_set = train_datagen.flow_from_directory(train_folder,\n",
        "                                                 target_size = (150, 150),\n",
        "                                                 batch_size = ____,\n",
        "                                                 class_mode = '____')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(val_folder,\n",
        "                                                        target_size =(150, 150),\n",
        "                                                        batch_size = ____,\n",
        "                                                        class_mode = '____')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(test_folder,\n",
        "                                            target_size = (150, 150),\n",
        "                                            batch_size = ____,\n",
        "                                            class_mode = '____')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "D0dSUoJ7z9Q5"
      },
      "outputs": [],
      "source": [
        "cnn_model = cnn.____(training_set,\n",
        "                    steps_per_epoch=____,\n",
        "                    epochs=____,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=____)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "To8qCVdk7kVV"
      },
      "outputs": [],
      "source": [
        "# Graficas de la presición y función de perdida\n",
        "\n",
        "acc = cnn_model.____['accuracy']\n",
        "val_acc = cnn_model.____['val_accuracy']\n",
        "loss = cnn_model.____['loss']\n",
        "val_loss = cnn_model.____['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 70\n",
        "plt.plot(____, ____, '-.r*', label='Exactitud en entrenamiento')\n",
        "plt.plot(____, ____, '-.b*', label='Exactitud en validación')\n",
        "plt.title('Exactitud en entrenamiento y validación')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, '-.r*', label='Pérdida en entrenamiento')\n",
        "plt.plot(epochs, val_loss, '-.b*', label='Pérdida en validación')\n",
        "plt.title('Pérdida en entrenamiento y validación')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SB_Pokp076UC"
      },
      "outputs": [],
      "source": [
        "test_accu = cnn.____(test_set,steps=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LPeL_peB8CDL"
      },
      "outputs": [],
      "source": [
        "print('La exactitud en el conjunto de prueba es: ',test_accu[1]*100, '%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn.save(____)\n",
        "cnn_fromFile = keras.models.load_model(____)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bSPXBOPi8Ija"
      },
      "outputs": [],
      "source": [
        "# Predicción sobre una imagen de prueba\n",
        "\n",
        "#img_ori = cv2.imread('/content/Neumonia_Dataset/test/NORMAL/IM-0011-0001-0002.jpeg')\n",
        "img_ori = cv2.imread('/content/Neumonia_Dataset/test/PNEUMONIA/person119_bacteria_566.jpeg')\n",
        "\n",
        "img_ori = cv2.cvtColor(img_ori, cv2.COLOR_BGR2RGB)\n",
        "img = cv2.____(img_ori, (150, 150), interpolation=cv2.INTER_CUBIC)\n",
        "imagen_a_probar = np.____(img,(1,150, 150, 3))\n",
        "predictions = ____.____(imagen_a_probar)\n",
        "if(predictions == 0):\n",
        "  print('Persona sin neumonia')\n",
        "else:\n",
        "  print('Persona con neumonia')\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clasificación de perros y gatos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!unzip -qq train.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "             keras.callbacks.ModelCheckpoint(\n",
        "                 filepath=\"convnet_keras.keras\",\n",
        "                 save_best_only=True,\n",
        "                 monitor=\"val_loss\"\n",
        "             )\n",
        "]\n",
        "\n",
        "history = model.fit(train_dataset, epochs=30, validation_data=validation_dataset, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graficas de la exactitud y función de pérdida\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 70\n",
        "plt.plot(epochs, acc, '-.r*', label='Exactitud en entrenamiento')\n",
        "plt.plot(epochs, val_acc, '-.b*', label='Exactitud en validación')\n",
        "plt.title('Exactitud en entrenamiento y validación')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, '-.r*', label='Pérdida en entrenamiento')\n",
        "plt.plot(epochs, val_loss, '-.b*', label='Pérdida en validación')\n",
        "plt.title('Pérdida en entrenamiento y validación')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(\"convnet_keras.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "     layers.RandomFlip(\"horizontal\"),\n",
        "     layers.RandomRotation(0.1),\n",
        "     layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_dataset.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3,3, i+1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180,180,3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "             keras.callbacks.ModelCheckpoint(\n",
        "                 filepath=\"convnet_keras_dataaug2.keras\",\n",
        "                 save_best_only=True,\n",
        "                 monitor=\"val_loss\"\n",
        "             )\n",
        "]\n",
        "\n",
        "history = model.fit(train_dataset, epochs=100, validation_data=validation_dataset, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"perros_gatos.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = load_model('perros_gatos.h5')\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img_ori = cv2.imread(\"gatito8.jpg\")\n",
        "img_ori = cv2.cvtColor(img_ori, cv2.COLOR_BGR2RGB)\n",
        "img = cv2.resize(img_ori, (180, 180), interpolation=cv2.INTER_CUBIC)\n",
        "imagen_a_probar = np.reshape(img, (1, 180, 180, 3))\n",
        "predictions = model.predict(imagen_a_probar)\n",
        "print(predictions)\n",
        "if predictions >= 0.5:\n",
        "  print(\"Se trata de un perrito\")\n",
        "else:\n",
        "  print(\"Se trata de un gatito\")\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Práctica 7. Sistemas Inteligentes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
